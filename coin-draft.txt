## Neural ensemble communities: Open-source approaches to hardware for large scale recording

Siegle JH, Hale G, Newman JP, Voigts J


Scientists preparing to test a hypothesis that would benefit from novel methods are commonly faced with a choice: Either invest in the training or personnel needed to build new tools for their lab, or outsource these efforts to companies that can sell them finished devices for obtaining quick and reliable results. Commercial equipment is often expensive, but it can reduce time to publication by eliminating the need to design and test customized lab kit.

Different fields gravitate to different ends of this spectrum between building and buying tools. In areas where technology changes slowly, commercial tools can improve efficiency by allowing researchers to focus on science rather than tool making. But there are instances in which they can hinder progress. Commercial tools are usually sold without access to the schematics or source code. For this reason, they are often treated as "black box" commodities that can be purchased but not modified, which limits the understanding of resulting data and extensibility of each tools' capabilities. As a result, experiments are often adjusted to fit the methods rather than vice versa— especially in cases where experimental needs weren't anticipated at the time when equipment was purchased. Furthermore, tools from different companies, even those designed for the same function, are often incompatible with one another. Once a system is chosen, future work may end up "locked in" to a particular system.

In fields where technical development is closely linked with the progress of scientific ideas, researchers are forced to build or modify their own tools in order to keep pace. In such environments, tools are often developed on the fly with no standardization or quality control, serving only the purpose of the current experiment. This approach sacrifices quality and reliability, but generally works because experimenters end up intimately familiar with their particular experiment. A similar situation often arises in labs that lack the funding for commercial tools.

Here, we examine the role that open-source development can play in extracellular electrophysiology, a widely used technique in neuroscience. We believe that, when designed properly, open-source tools can provide the best of both worlds by combining the quality, ease of use, and support of commercial products with the high performance and adaptability of locally developed tools.

Extracellular recording electrodes were one of the earliest tools for investigating brain function, and are now one of the most rapidly evolving. We believe that the community of scientists using these methods is ideally positioned to benefit from open-source development. Crucially, the recent emergence of collaborative design tools and affordable manufacturing have made the open-source model competitive with commerical options. Here, we present arguments for and against the need for open-source hardware for high-channel-count electrophysiology, which also apply to other neuroscientific techniques.

#2A Electrophysiology is well-suited for an open development model

In the simplest case, recording electrical signals from the brain only requires two conductors to measure a potential difference, a means of amplifying that difference, and a method to store changes in this signal over time. A century ago, nerve impulses were being amplified using vacuum tubes and recorded on photographic film scanned behind a mercury column {Adrian 1926}. Today, mass-produced circuits costing a few dollars can be used to amplify neural signals and store them digitally{CITATION}. In recent years, there has been a push to record from many channels simultaneously in order to understand the brain at the network level{CITATION - brain project etc}. Simultaneously, experimental desing is becoming more complex and now often requires equipment that can manipulate rather than just record neural activity.

For the most part, these advances in recording and stimulation technology have occured within individual labs and were then commercialized and distributed to the wider community. The resulting systems are typically monolithic and closed. Some of the major vendors of commercial data acquisition systems are Neuralynx, Plexon, Blackrock, Tucker-Davis Technologies, Ripple, and Axona [any others to add???]. By giving researchers access to high-quality, professionally tested tools, as well as reliable support services, these companies have been essential to the proliferation of multichannel electrophysiology systems over the past two decades. However, it is no longer clear that these services should be provided exclusively by commercial entities.

We see three reasons why the current model of tool development and distribution would benefit from an active open-source community:

1. Electrode technology is advancing rapidly. Experimenters using twisted-wire tetrodes are packing more electrodes into a smaller area{CITATIONS}, silicon probes are becoming thinner and denser{CITATIONS}, and active probes are under development{CITATIONS}. Researchers need the flexibility to choose the option that is best-suited to their particular application, which can include mixing technologies. Companies that implement proprietary standards often prevent this. One recent example of this is the development of amplifier chips by Intan technologies which can amplify and digitize up to 64 channels of neural data in an 8 x 8 mm package. When integrated into a "headstage" (the interface that connects electrodes to a data acquisition system), Intan chips offer considerable advantages over their analog counterparts. For this reason, nearly every major vendor now sells headstages that use Intan chips, but none of them are interchangeable. Users are stuck with whatever connectors the vendors have chosen to provide, and cannot customize them without the help of the manufacturer.

2. On the software side, the requirements for analysis and visualization vary greatly between labs, and even between experiments. Specialized algorithms are needed to handle electrophysiological data once it reaches the computer, especially when closed-loop feedback is required. It's often impossible to predict which algorithms will work best before the experiments have been run. An example of this is online spike-sorting, which allows researchers to measure the activity of single neurons near their electrodes. A few commercial systems already implement this method, but use different algorithms that are often not fully disclosed. This makes it difficult or impossible to directly compare data collected across different labs {Cohen 2011}.

3. There is currently large amounts of redundant tool development going on within each lab. Electrophysiologists tend to be technically savvy and favor a "do it yourself" approach. Some of this is cultural, but much of it is out of necessity. The complexity of neurological systems has forced many electrophysiologists to take matters into their own hands, and develop customized hardware and software for their experiments. Unfortunately, very little of this development is shared, leading to a huge amount of redundant effort within and across laboratories.

These reasons, which are not unique to extracellular electrophysiology, make it likely that a shift toward a more open development model will occur in the near future.

#2B A brief history of open-source approaches

Since the widespread adoption of multichannel recording techniques, there have been several attempts to develop open-source recording platforms that are polished enough and sufficiently well documented to propagate beyond the labs that invented them.

## A/D
In the early 1990s, A/D... (someone should ask Matt about this to get the history right).

Should we mention the large time gap? Or are there tools we don't know about?
JPN - I'm going to interview Daniel Wagenaar and Bruce Wheeler, two of the early technically minded people in the planar MEA world, to see if they have any ideas about this. Are their others to talk to about the in vivo side of things. Its important to remember that during this time github etc did not exist, so code sharing was pretty ad hoc. I think mentioning this would be good because it indicates that the growth of infrastructure supporting open hardware and software mirrored the popularity of the idea in general.

## MEABench
MEABench is a set of Linux command line programs for acquiring, processing, and saving multielectrode voltages from planar microelectrode arrays (MEAs). MEABench was created in 2005 by Daniel Wagenaar, Tom Demarse, and Steve Potter. Each MEABench program applies a single function, such as 'Filter' or 'Record', to a multichannel data stream. Each program uses standardized inter-process streaming interface, allowing programs to be daisy-chained and branched in order to construct complex signal processing arrangements. Although MEABench does not provide native support for closed-loop experiments, it can combined with real-time simulation tools~\citep{Wagenaar2002} using custom ‘glue’ programs to create feedback loops~\citep{Wagenaar2005}. MEABench has limited hardware driver support and currently only works with outdated and very expensive MCS data acquisition cards. However, the modularity and reconfigurability of MEABench have inspired more modern, extensible, easy-to-use open-source solutions.

## NeuroRighter
The introduction high channel count data aquisition cards produced by National Instuments in the mid-2000's led the Potter lab to develop a second open-source electrophysiology platform called NeuroRighter. NeuroRighter was created by John Rolson, Jon Newman, and Riley Zeller-Townson. NeuroRighter significantly reduced the cost of multichannel data acqusition for MEAs compared to MEABench from ~65,000 to ~10,000 USD. To increase usability compared to MEABench, NeuroRighter operates as a standalone application with graphical control over filter and amplifier settings, online spike-sorting, data visualization, and data storage {Rolston 2009}. Further, NeuroRighter integrated native support for real-time feedback. NeuroRighter's data processing pipeline can be augmented using an appilcation programing interface to create 'plugin' libraries that can be executed by NeuroRighter as it operates {Newman 2012}. The NeuroRigher API also supports electrical and optical stimulation protocols, so that closed-loop experimentation is possible.

## ArtE
The A/D system targeted DOS and data acquisition cards that restricted its use to 486 computers. The degree of bitrot and increasing difficulty of finding sufficiently dated replacement hardware motivated a total rewrite, targeting contemporary acquisition cards and Linux - a far less hostile environment for software development. This project's name, ArtE (Almost Realtime Electrophysiology), reflects the intention to provide neural feedback during an experiment. In addition to feature parity with A/D, ArtE was designed to run in parallel with an existing A/D system, for the purpose of bootstrapping development and testing recorded spikes against a thoroughly debugged standard viewing the exact same data. The requirement to run alongside a very different system forced ArtE to be modular, with data moving between independent processes running on different machines over the network, in the spirit of MEABench.

## Open Ephys
The public release of integrated amplifier chips by Intan Technologies in 2009?{CITATION} made it possible to circumvent the National Instruments analog-to-digital conversion hardware that was a part of all the previous platforms. The co-founders of the Open Ephys initiative, Josh Siegle and Jakob Voigts, designed a system based on these chips, with reduced hardware complexity and an order of magnitude drop in equipment cost compared to ArtE and NeuroRighter. The development and support of open interfaces by Intan (RHD2000 SPI protocol and Rhythm firmware and API) made the process simpler and made the tools compatible with hardware and software from Intan. The low price to manufacture each acquisition board (~$700 per unit in bulk), allowed Open Ephys to distribute the tools widely in a short period of time. There are currently over 80 labs with Open Ephys hardware.

What drove the development and increased adoption of these open source tools? There are a few key factors that have recently allowed open-source tools to rival, and in some ways, surpass the functionality of their commercial counterparts. First of, thanks to their openness, all of the listed systems were to some degree built upon and improving upon each-other's designs. NeuroRighter was created to simplify MEABench, ArtE was inspired by the efforts of NeuroRighter, and the Open Ephys software began as a graphical interface for ArtE. Different requirements caused these systems to diverge, but there is no reason that they couldn't be made cross-compatible, or continue to benefit from cross-pollination of ideas.

In parallel to this, developments not directly related to neuroscience contributed to the increasing quality of open-source tools.

1. Smaller, cheaper and better hardware. Market forces are pushing for ever smaller and cheaper processors and other components that are drive cellular phones and portable devices and can be used in scientific equipment.

2. Tools for collaborative design. The rise of tools for collaborative design such as GitHub (based on the git software written by Linus Torvalds) make it easy for researchers to develop high quality software and hardware. Wikis enable distributed, constantly updated documentation.

3. The open-source hardware movement. Products like Arduino, Raspberry Pi, and Beaglebone make it easy and cheap to use high-powered embedded computations. Many neuroscientists get their start in hardware design using simple platforms like Arduino, and then graduate to more powerful systems. They also set a precedent for what good open-source design should be: simple to comprehend, highly adaptable, and well-documented.

#2C Open interfaces: a middle-of-the-road solution

Taking cues from these widely adopted open-source platforms, we propose an open approach to hardware and software development for extracellular electrophysiology that centers around standardized interfaces and modular architecture. If it's embraced by both researchers and commercial suppliers, it could greatly improve the productivity of the community. The essence of this proposal is that the most common interfaces (e.g. electrode-to-headstage, headstage-to-cable, data-to-computer) should become standardized, so that anyone can make tools that fit into the same pipeline. Similar standards already exist in many other ecosystems, such as audio recording, where microphones, analog-to-digital converters, and processing software can come from different companies, yet work seamlessly together.

There is no reason to circumvent the technical expertise accumulated by existing companies. In a model where system components are modular, well documented, and interchangeable, companies could diversify and concentrate their resources. Rather than developing and supporting entire systems, they could focus on making the highest-quality components within a modular system. This could be in collaboration with scientists that come up with ideas that require new tools, or already have prototypes that aren't ready for distribution. Additionally, standardized equipment should create a market for professional support for existing systems, similar to how companies sell support contracts for Linux-based systems rather than the software itself.

There is also no fundamental reason why all components of electrophysiology systems need to be open-source. Even the most "open" tools make use of "black boxes" in the form of well-documented, but closed-source integrated circuits. These circuits perform specified functions ranging from amplifiers and filters up to FPGAs and processors. As long as the behavior of a component is well-defined, and its interfaces are documented and adhere to standards, closed-source components are no obstacle to the functionality of the whole system. In figure 1, we illustrate some of the interfaces for multichannel electrophysiology that would benefit most from standardization.

The same principle applies to the software used to visualize and record data. Currently,  most commercial software is tied to specific hardware, which leads to a huge amount of redundancy and lock-in. For the same reasons that we need modular hardware, modular software will become crucial in coming years. Higher channel counts demand that processing be done in real time, and many experiments would benefit from closed-loop processing. If there's no standard interface for this, researchers will end up replicating the same code many times for many different platforms. Further, the more processing is done in real time, the more difficult it will be to compare the results of experiments collected on different platform.

#3 Conclusion

When selecting a platform for multichannel extracellular electrophysiology, the gap between open-source and closed-source solutions is no longer as wide as it used to be. There now exists plug-and-play open-source hardware, and some commercial companies have developed open-source software or application programming interfaces (APIs) that allow end-users to customize their software. Currently, open-source systems are cheaper and offer higher flexibility, while closed-source systems offer professional support, but there is no fundamental reason why  this distinction will hold for the future.

Because the landscape of extracellular electrophysiology is changing so rapidly, we advocate for the development of standardized interfaces that will allow open-source and closed-source tools to work together. This would give the end users the option to employ a home-built solution when necessary, while relying on canned solutions at other points in the pipeline, or working with a company to develop specialized components for another. The move toward open interfaces is unlikely to happen naturally; electrophysiologists must start demanding openness wherever possible. Open interfaces will ultimately result in less time spent on redundant development efforts, but only if they are actively promoted and financially supported by the labs and funding agencies that stand to benefit from them.
