## Neural ensemble communities: Open-source approaches to hardware for large scale recording

Siegle JH, Hale G, Newman JP, Voigts J


Scientists preparing to test a hypothesis that would benefit from novel methods are commonly faced with a choice: Either invest in the training or personnel needed to build new tools for their lab, or outsource these efforts to companies that can sell them finished devices for obtaining quick and reliable results. Commercial equipment is often expensive, but it can reduce time to publication by eliminating the need to design and test customized lab kit.

Different fields gravitate to different ends of this spectrum between building and buying their tools. In cases in which the available technology changes slowly, commercial tools can improve efficiency by allowing researchers to focus on science rather than tool making. But there are instances in which commercial tools can hinder progress. Commercial tools are usually sold without access to the schematics or source code required to check the validity of results or to re-run experiments and analyses with different parameters. For this reason, they are often treated as "black box" commodities that can be purchased but not modified, which limits the understanding of resulting data and extensibility of each tools' capabilities. As a result, experiments are often adjusted to fit the available methods rather than vice versa—especially in cases where experimental needs weren't anticipated at the time when equipment was purchased. Furthermore, tools from different companies, even those designed for the same function, are often incompatible with one another. Once a system is chosen, future work may end up "locked in" to a particular system.

In fields where technical development is closely linked with the progress of scientific ideas, researchers are forced to build or modify their own tools in order to keep pace with their competitors. In such an environment, tools are often developed on the fly with no standardization or quality control, serving only the purpose of the current experiment. This approach sacrifices quality and reliability, but generally works because experimenters are intimately familiar with the function of their particular experiment. A similar situation often arises in labs that lack the funding for commercial tools, or in labs that want to add new techniques to their repertoire without committing a lot of resources.

In this article, we examine the role that open-source development can play in extracellular electrophysiology, a widely used technique in neuroscience. We believe that, when designed properly, open-source tools can provide the best of both worlds by combining the quality, ease of use, and support of commercial products with the high performance and adaptability of locally developed tools.

Extracellular recording electrodes were one of the earliest tools for investigating brain function, and are now one of the most rapidly evolving. We believe that the community of scientists using these methods is ideally positioned to benefit from an open approach to technical development. A recent wave of open-source tools for electrophysiology provide a useful starting point{CITATIONS}. Crucially, the parallel growth of platforms for collaborative design and affordable standardized manufacturing have now recently made the open-source model competitive with commerical options. Below, we present arguments for and against the need for open-source hardware for high-channel-count electrophysiology, which also apply to other neuroscientific techniques.

#2A Electrophysiology is well-suited for an open development model

Recording electrical signals from the brain is a straightforward proposition. In the simplest case, it only requires two conductors to measure a potential difference, a means of amplifying that difference, and a method to store changes in the amplified signal over time. A century ago, nerve impulses were being amplified using vacuum tubes and recorded on photographic film scanned behind a mercury column {Adrian 1926}. Today, mass-produced circuits costing a few dollars can be used to amplify neural signals and store them digitally{CITATION}.

The technologies involved in extracellular electrophysiology are far from stagnant. In recent years, there has been a push to record from more channels simultaneously in order to understand the brain at the network level{CITATION - brain project etc}. Making sense of these complex networks requires equipment that can update experimental parameters as data is being collected, rather than using pre-determined stimuli.

For the most part, advances in recording and stimulation technology occur within individual labs. Companies then take these advances, optimize them for general usability, and distribute them to the wider community. The resulting systems are typically monolithic, in that all the parts are designed by the same company, and closed, in that the hardware designs and source code are not publicly available. Some of the major vendors of commercial data acquisition systems are Neuralynx, Plexon, Blackrock, Tucker-Davis Technologies, Ripple, and Axona [any others to add???]. By giving researchers access to high-quality, professionally tested tools, as well as reliable support services, these companies have been essential to the proliferation of multichannel electrophysiology systems over the past two decades. However, it is no longer clear that these services should be provided exclusively by commercial entities.

We see three reasons why the current model of tool development and distribution would benefit from an active open-source community:

1. Electrode technology is advancing rapidly. Experimenters using twisted-wire tetrodes are packing more electrodes into a smaller area{CITATIONS}, silicon probes are becoming thinner and denser{CITATIONS}, and active probes are under development{CITATIONS}. Researchers need the flexibility to choose the option that is best-suited to their particular application, and need to be able to mix-and match electrode types. Unfortunately, vendor lock-in can prevent this. Companies have trouble keeping up with the latest advances, and when they do, they often implement proprietary standards that Balkanize the field. One recent example of this is the development of amplifier chips from Intan technologies, which can amplify and digitize 32 channels of neural data in an 8 x 8 mm package. When integrated into a "headstage" (the temporary interface that connects implanted electrodes to a data acquisition system), systems based on Intan chips offer considerable advantages over their analog counterparts. For this reason, nearly every major vendor now sells headstages that use Intan chips for digitization, but none of them are interchangeable. Users are stuck with whatever connectors the vendors have chosen to provide, and cannot customize them without the help of the manufacturer.

2. On the software side, the requirements for analysis and visualization vary greatly from researcher to researcher, and even from experiment to experiment. Specialized algorithms are needed to handle electrophysiological data once it reaches the computer, especially when closed-loop feedback is involved. It's often difficult for researchers to predict which algorithms will be necessary before the experiments have been run. An example of this is online spike-sorting, which allows researchers to probe the response properties of single units near their recording electrode. Certain commercial software may or may not implement this, and they may all use different algorithms. Further, the exact mathematical method used to project spike waveforms into a feature space and segmenting feature clusters is often not disclosed. This makes it difficult or impossible to directly compare data collected across different data acquisition platforms platforms{Cohen 2011}.

3. There is currently large amounts of redundant tool development going on within each lab. Electrophysiologists tend to be technically savvy and favor a "do it yourself" approach to their work. Some of this is cultural, but much of it is out of necessity. The complexity of neurological systems combined with the limiting nature of commercially available products has forced many electrophysiologists to take matters into their own hands, and develop customized hardware and software for their experiments. Unfortunately, very little of this development is shared, leading to a huge amount of redundant effort within and across laboratories.

These reasons, which are not unique to extracellular electrophysiology, make it likely that a shift toward a more open development model will occur in the near future.

#2B A brief history of open-source approaches

The development of custom tools is often a fact of life in extracellular electrophysiology labs. Sometimes it's done out of necessity, in cases where commercial suppliers simply do not exist; other times it's done out of principle, to provide peace of mind to researchers who want to know how their tools work at every level. Since the widespread adoption of multichannel recording techniques, there have been several attempts to develop open-source recording platforms that are polished enough and sufficiently well documented to propagate beyond the labs that invented them.

## A/D
In the early 1990s, A/D... (someone should ask Matt about this to get the history right).

Should we mention the large time gap? Or are there tools we don't know about?
JPN - I'm going to interview Daniel Wagenaar and Bruce Wheeler, two of the early technically minded people in the planar MEA world, to see if they have any ideas about this. Are their others to talk to about the in vivo side of things. Its important to remember that during this time github etc did not exist, so code sharing was pretty ad hoc. I think mentioning this would be good because it indicates that the growth of infrastructure supporting open hardware and software mirrored the popularity of the idea in general.

## MEABench
MEABench is a set of Linux command line programs for acquiring, processing, and saving multielectrode voltages from planar microelectrode arrays (MEAs). MEABench was created in 2005 by Daniel Wagenaar, Tom Demarse, and Steve Potter. Each MEABench program applies a single function, such as 'Filter' or 'Record', to a multichannel data stream. Each program uses standardized inter-process streaming interface, allowing programs to be daisy-chained and branched in order to construct complex signal processing arrangements. Although MEABench does not provide native support for closed-loop experiments, it can combined with real-time simulation tools~\citep{Wagenaar2002} using custom ‘glue’ programs to create feedback loops~\citep{Wagenaar2005}. MEABench has limited hardware driver support and currently only works with outdated and very expensive MCS data acquisition cards. However, the modularity and reconfigurability of MEABench have inspired more modern, extensible, easy-to-use open-source solutions.

## NeuroRighter
The introduction high channel count data aquisition cards produced by National Instuments in the mid-2000's led the Potter lab to develop a second open-source electrophysiology platform called NeuroRighter. NeuroRighter was created by John Rolson, Jon Newman, and Riley Zeller-Townson. NeuroRighter significantly reduced the cost of multichannel data acqusition for MEAs compared to MEABench from ~65,000 to ~10,000 USD. To increase usability compared to MEABench, NeuroRighter operates as a standalone application with graphical control over filter and amplifier settings, online spike-sorting, data visualization, and data storage {Rolston 2009}. Further, NeuroRighter integrated native support for real-time feedback. NeuroRighter's data processing pipeline can be augmented using an appilcation programing interface to create 'plugin' libraries that can be executed by NeuroRighter as it operates {Newman 2012}. The NeuroRigher API also supports electrical and optical stimulation protocols, so that closed-loop experimentation is possible.

## ArtE
2010 - ArtE - Greg should write this

## Open Ephys
The public release of integrated amplifier chips by Intan Technologies in 2009?{CITATION} made it possible to circumvent the National Instruments analog-to-digital conversion hardware that was a part of all the previous platforms. The co-founders of the Open Ephys initiative, Josh Siegle and Jakob Voigts, designed a system based on these chips, with reduced hardware complexity and an order of magnitude drop in equipment cost compared to ArtE and NeuroRighter. The development and promotion of open interfaces by Intan (RHD2000 SPI protocol and Rhythm FPGA firmware) made the process much simpler by reducing the number of design decisions and making their tools compatible with pre-existing hardware and software from Intan. The low price to manufacture each acquisition board (~$700 per unit in bulk), allowed Open Ephys to distribute the tools widely in a short period of time. There are currently over 80 labs with Open Ephys hardware.

What drove the development and increased adoption of these open source tools? There are a few key factors that have recently allowed open-source tools to rival (and in some ways, surpass) the functionality of their commercial counterparts. First of, thanks to their openness, all of the listed systems were to some degree built upon and improving upon each-other's designs. NeuroRighter was created to simplify MEABench, ArtE was inspired by the efforts of NeuroRighter, and the Open Ephys software began as a graphical interface for ArtE. Different requirements caused these systems to diverge, but there is no reason that they couldn't be made cross-compatible, or continue to benefit from cross-pollination of ideas.

In parallel to this, developments not directly related to neuroscience contributed to the increasing quality of open-source tools.

1. Smaller, cheaper hardware. Market forces are pushing for ever smaller and cheaper processors and other components that are contained in cellular phones and portable devices. When these become publicly available, they simplify the design process for neuroscientists.

2. Tools for collaborative design. The rise of the Internet, which led to an explosion of tools for "social design." GitHub is a website that makes it easy for researchers to collaboratively develop software and hardware, based on the powerful git software written by Linus Torvalds, the creator of Linux. Wikis allow documentation to be distributed across the community, and to be updated instantly. On a more mundane level, email and video conferencing make it more common to trust developers that one hasn't ever met in person. 

3. The open-source hardware movement. Products like Arduino, Raspberry Pi, and Beaglebone make it easy to harness high-powered embedded computations at a low price, and low barrier to entry. Many neuroscientists get their start in hardware design using simple platforms like Arduino, and then graduate to more powerful systems. They also set a precedent for what good open-source design should be: simple to comprehend, highly adaptable, and well-documented.

#2C Open interfaces: a middle-of-the-road solution

Taking cues from these widely adopted open-source platforms, we propose an open approach to hardware and software development for extracellular electrophysiology that centers around standardized interfaces and modular architecture. If it's embraced by both researchers and commercial suppliers, it could greatly improve the productivity of the community. The essence of this proposal is that the most common interfaces (e.g. electrode-to-headstage, headstage-to-cable, data-to-computer) become standardized, so that anyone can make tools that fit into the same pipeline. This is what already exists in many other ecosystems, such as audio recording, where microphones, analog-to-digital converters, and processing software can come from different companies, yet work seamlessly together.

There is no reason to circumvent the technical expertise accumulated by commercial tool developers. In a model where system components are modular, well documented, and interchangeable, companies could diversify and concentrate their resources. Rather than developing and supporting entire systems, they could focus on making the highest-quality components within a modular system. This development could be done in collaboration with scientists that come up with ideas for require new tools, or already have prototypes that aren't ready for distribution. Additionally, standardized equipment should give rise to an even bigger market for professional support for existing systems, similar to how companies sell support for Linux-based systems rather than commoditizing the software itself.

There is no fundamental reason why all components of electrophysiology systems need to be open-source. Even the most "open" tools make heavy use of "black boxes" in the form of well-documented, but closed-source integrated circuits. These circuits perform specified functions ranging from amplifiers and filters up to FPGAs and processors. As long as the behavior of a component is well-defined, and its interfaces are documented and adhere to standards wherever possible, closed-source components are not necessarily an obstacle to the functionality of the whole system. The key requirement is that tools need to allow researchers to choose their path, and have options at each point. In figure 1, we illustrate some of the interfaces for multichannel electrophysiology that would benefit most from standardization.

The same principle applies to the software used to visualize and record data streaming from the hardware. Currently, the software provided by commercial companies is tied to specific hardware. There is no general-purpose software for neuroscience experiments, which leads to a huge amount of redundancy and lock-in. For the same reasons that we need modular hardware, modular software will become crucial in coming years. Higher channel counts demand that processing be done in real time, and many experiments would benefit from closed-loop processing. If there's no standard interface for this, researchers will end up replicating the same code many times for many different platforms. And the more processing that is done in real time, the more difficult it will be to compare the results of experiments collected on different platform.


#3 Conclusion

When selecting a platform for multichannel extracellular electrophysiology, the gap between open-source and closed-source solutions is no longer as wide as it used to be. There now exists plug-and-play open-source hardware, and some commercial companies have developed open-source software or open application programming interfaces (APIs) that give end-users to customize the actions of their acquisition boards. In general, open-source systems can be obtained at a lower cost and offer higher flexibility, while closed-source systems come with the guarantee of professional support. But these guidelines could change in the near future. If commercial companies adopt some of the rapid-prototyping techniques employed by open-source initiatives, they could radically bring down manufacturing costs. And as open-source platforms gain traction, the distributed assistance provided by forums and wiki-like documentation could surpass the convenience of professional support.

Because the landscape of extracellular electrophysiology is changing so rapidly, we advocate for the development of standardized interfaces that will allow open-source and closed-source tools to work together. This would give the end users the option to employ a custom solution when necessary, while relying on canned solutions at other points in the pipeline. The move toward open interfaces is unlikely to happen naturally; electrophysiologists must start demanding openness wherever possible. Open interfaces will ultimately result in less time spent on redundant development efforts, but only if they are actively promoted and financially supported by the labs and funding agencies that stand to benefit from them.




